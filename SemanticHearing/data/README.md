# Sourcing audio from multiple datasets
As described in the paper, we source our audio files from four datasets: FSD50K, ESC-50, MUSDB18 and noise files from the DISCO dataset.

Since our training and evaluation procedures make use of the Python Scaper library, we need to organize the data files in a way that the Scaper format. This happens in a multi-step procedure.

## Generating splits and mapping classes to AudioSet

First, for each dataset we source from, we need to create three CSV files, one for each of the data splits (train, test and val). The CSV files contain some useful information about each audio file, ex: the sound classes and AudioSet ID of each file. These CSV files are also used to map classes that are outside of the AudioSet ontology into the closest label in the ontology.

These CSV files are generated by a dedicated python script for each dataset. They can be found in ```data/compile/{DATASET_NAME}_label_collector.py```. For example, the script to generate the CSV files for FSD50K can be found in ```data/compile/fsd50k_label_collector.py```.

## Consolidating (uniting) splits from multiple dataset into a scaper format

Once we have a description for each file in each dataset, given by the generated CSV files in the previous step, we now need to organize these audio files in the appropriate format to create JAMS files using Scaper. We to create two distinct directories, one for background sounds (not in our target sound classes), and one for foreground sounds (user can choose these classes). The foreground sounds are enumerated in ```data/Classes.yaml```. Here, we define the name of the class (as defined in our project), and what AudioSet classes belong to this class. You can move audio classes to and from the foreground set by changing this definition file. 

We consider the AudioSet ontology as a directed graph, where nodes are the audio classes and the edges are directed from an audio class to all its specialized sound classes. For example, if we consider the node "Aircraft", then there are edges from this node to each of "Aircraft engine", "Helicopter" and "Fixed-wing aircraft, airplane". 

When picking sound examples for a particular sound class, we choose all audio files that contain only nodes reachable from this class. These audio files will be placed in the directory of foreground sounds for this audio class. 

Roughly speaking, if an audio file is not part of our foreground set, then we consider it as a background sound. Specifically, audio files that are not included in the ```data/Classes.yaml``` and do not contain a sound class that is reachable from any foreground class is placed in the directory of background sounds.

Audio files are placed into the Scaper directories by creating symbolic links, so as not to increase dataset size. In addition to organizing the audio files in this way, the dataset consolidation step also creates a CSV containing the start and end times of the sounds in each file, which is useful when creating audio mixtures.

This step is done in ```data/compile/consolidate_datasets.py```. Note that this file is set up to call all the label collection scripts before writing the symlinks. Once you finish this step, you can create JAMS files using Scaper.
